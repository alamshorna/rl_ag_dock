{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03f6681-4477-4afe-a406-bd29f977d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start, let's try to implement a REINFORCE algorithm (policy gradient)\n",
    "# we only need some sort of featurizer, \n",
    "# a policy graph network, \n",
    "# and the reinforcement learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed855911-7c18-4526-a48a-a9878d6e5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # note: code borrowed from gaeun\n",
    "import os \n",
    "import yaml\n",
    "\n",
    "yamls_path = \"/project/liulab/gkim/antigen_prediction/eval_boltz_on_sabdab/all_yaml_outdir\"\n",
    "pdbs_path = \"/project/liulab/gkim/antigen_prediction/data/renumbered_sabdab_pdb_files/pdb_files\"\n",
    "\n",
    "def get_chain_info_from_pdb(pdb_path, yaml_path):\n",
    "    \"\"\"Get chain information from YAML file.\"\"\"    \n",
    "    if not os.path.exists(pdb_path):\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    if not os.path.exists(yaml_path):\n",
    "        print(f\"No YAML file found at {yaml_path}\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            yaml_data = yaml.safe_load(f)\n",
    "        \n",
    "        # Extract chain IDs and sequences from YAML data\n",
    "        # Assume the first sequence is heavy and the second sequence is light\n",
    "        # UNLESS there are more than 2 sequences\n",
    "        h_chain = None\n",
    "        l_chain = None\n",
    "        h_seq_yaml = None\n",
    "        l_seq_yaml = None\n",
    "\n",
    "        # Look for sequences in the YAML data\n",
    "        if 'sequences' in yaml_data and isinstance(yaml_data['sequences'], list):\n",
    "            sequences = yaml_data['sequences']\n",
    "            if len(sequences) == 2:\n",
    "                h_chain = sequences[0]['protein']['id']  # First sequence is heavy\n",
    "                l_chain = sequences[1]['protein']['id']  # Second sequence is light\n",
    "                h_seq_yaml = sequences[0]['protein']['sequence']\n",
    "                l_seq_yaml = sequences[1]['protein']['sequence']\n",
    "            elif len(sequences) > 2:\n",
    "                # first sequence is antigen (for multimer predictions)\n",
    "                h_chain = sequences[1]['protein']['id']  # Second sequence is heavy\n",
    "                l_chain = sequences[2]['protein']['id']  # Third sequence is light\n",
    "                h_seq_yaml = sequences[1]['protein']['sequence']\n",
    "                l_seq_yaml = sequences[2]['protein']['sequence']\n",
    "        \n",
    "        if 'antigen' in yaml_data and isinstance(yaml_data['antigen'], list):\n",
    "            antigen = yaml_data['antigen'][0]['protein']['sequence']\n",
    "        else:\n",
    "            antigen = None\n",
    "        \n",
    "        return h_chain, l_chain, h_seq_yaml, l_seq_yaml, antigen\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading YAML file for {yaml_path}: {e}\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0625a31-544e-4346-9b53-b4f49da6c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sd_pd = pd.read_csv(\"sabdab_summary_all.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37f5fd0-d4a2-4570-bacb-3c391a4a038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB.Polypeptide import three_to_index\n",
    "\n",
    "def featurizer(heavy_chain, ag_chain, device='cpu'):\n",
    "    # https://towardsdatascience.com/graph-convolutional-networks-introduction-to-gnns-24b3f60d6c95/\n",
    "    # node feature matrix with shape (number of nodes, number of features)\n",
    "    # graph connectivity (how the nodes are connected) with shape (2, number of directed edges)\n",
    "    # node ground-truth labels. In this problem, every node is assigned to one class (group)\n",
    "\n",
    "    # # construct the distance matrix\n",
    "    heavy_coords = np.array([res['CA'].coord for res in heavy_chain if 'CA' in res])\n",
    "    antigen_coords = np.array([res['CA'].coord for res in ag_chain if 'CA' in res])\n",
    "    antigen_residues = np.array([int(res.id[1]) for res in ag_chain if 'CA' in res])\n",
    "    \n",
    "    dist_matrix = np.linalg.norm(\n",
    "        heavy_coords[:, np.newaxis, :] - antigen_coords[np.newaxis, :, :],\n",
    "        axis=-1\n",
    "    )\n",
    "    # https://numpy.org/devdocs/reference/generated/numpy.argpartition.html\n",
    "    # only sort the bottom k\n",
    "    bottom_k = np.argpartition(dist_matrix.flatten(), k)[:k]\n",
    "    # flatten and unravel :)\n",
    "    bottom_k_indices = np.unravel_index(bottom_k, dist_matrix.shape)\n",
    "\n",
    "    residues = bottom_k_indices\n",
    "    \n",
    "    def matrix_idx_to_resnum(chain, matrix_idx_list):\n",
    "        ca_residues = [res for res in chain if 'CA' in res]\n",
    "        return [int(ca_residues[i].id[1]) for i in matrix_idx_list]\n",
    "\n",
    "    # Convert matrix indices → PDB residue numbers\n",
    "    heavy_residues = matrix_idx_to_resnum(heavy_chain, list(dict.fromkeys(residues[0])))\n",
    "    ag_residues    = matrix_idx_to_resnum(ag_chain, list(dict.fromkeys(residues[1])))\n",
    "    \n",
    "    # matrix indices (0..N-1) → PDB residue numbers\n",
    "    heavy_id_map = [int(res.id[1]) for res in heavy_chain if 'CA' in res]\n",
    "    ag_id_map    = [int(res.id[1]) for res in ag_chain if 'CA' in res]\n",
    "\n",
    "    # pdb residue numbers of the heavy and antigen residues\n",
    "    heavy_residues = [heavy_id_map[item.item()] for item in list(dict.fromkeys(residues[0]))]\n",
    "    ag_residues = [ag_id_map[item.item()] for item in list(dict.fromkeys(residues[1]))]\n",
    "\n",
    "    node_features = torch.zeros(len(heavy_residues + ag_residues), 2, device=device) # chain, residue_id\n",
    "    \n",
    "    heavy_idx_to_node_idx = {res_idx: i for i, res_idx in enumerate(heavy_residues)}\n",
    "    ag_idx_to_node_idx = {res_idx: i + len(heavy_residues) for i, res_idx in enumerate(ag_residues)}\n",
    "\n",
    "    # heavy chains are \"0\" and antigen chains are \"1\"\n",
    "    for i, res_idx in enumerate(heavy_residues + ag_residues):\n",
    "        if i < len(heavy_residues):\n",
    "            res_idx = heavy_id_map[i]\n",
    "            node_features[i][0] = 0\n",
    "            node_features[i][1] = three_to_index(heavy_chain[res_idx].get_resname())\n",
    "        else:\n",
    "            res_idx = ag_id_map[i - len(heavy_residues)]\n",
    "            node_features[i][0] = 1\n",
    "            node_features[i][1] = three_to_index(ag_chain[res_idx].get_resname())\n",
    "\n",
    "    # node_features = node_features.T\n",
    "    \n",
    "    hc_nodes = torch.tensor([heavy_idx_to_node_idx[matrix_idx_to_resnum(heavy_chain, [id.item()])[0]] \n",
    "                             for id in residues[0]], device=device)\n",
    "    ag_nodes = torch.tensor([ag_idx_to_node_idx[matrix_idx_to_resnum(ag_chain, [id.item()])[0]] \n",
    "                             for id in residues[1]], device=device)\n",
    "    # print(torch.vstack((hc_nodes, ag_nodes)).shape)\n",
    "    # print(torch.vstack((hc_nodes, ag_nodes)).T.shape)\n",
    "    # raise Exception\n",
    "    edge_connections = torch.vstack((hc_nodes, ag_nodes))\n",
    "    \n",
    "    num_edges = edge_connections.T.shape[0]\n",
    "    edge_features = torch.zeros(num_edges, 1, device=device)\n",
    "    for j, (a, b) in enumerate(zip(residues[0], residues[1])):\n",
    "        edge_features[j] = dist_matrix[a, b].item()\n",
    "    # edge_features = edge_features\n",
    "        \n",
    "    return node_features, edge_connections, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb75ee9-06bd-4840-95a8-926af773f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing YAML files: 100%|██████████| 10/10 [00:00<00:00, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Chain id=H>, <Chain id=F>, <Chain id=H>, <Chain id=C>] [<Chain id=C>, <Chain id=D>, <Chain id=A>, <Chain id=A>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "k = 12\n",
    "\n",
    "from Bio.PDB import PDBList, PDBParser, Select, PDBIO\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "heavy_chains, antigen_chains = [], []\n",
    "for yaml_file in tqdm(os.listdir(yamls_path)[:10], desc=\"Processing YAML files\"):\n",
    "    yaml_path = os.path.join(yamls_path, yaml_file)\n",
    "    name = yaml_file.split('.')[0]\n",
    "    pdb_file = name + '.pdb'\n",
    "    pdb_path = os.path.join(pdbs_path, pdb_file)\n",
    "    # we'll use Gauen's function because it already maps from the name to the pdb that is already downloaded on the server...\n",
    "    h, l, _, _, _ = get_chain_info_from_pdb(pdb_path, yaml_path)\n",
    "    row = sd_pd[(sd_pd[\"pdb\"] == name) & (sd_pd[\"Hchain\"] == h) & (sd_pd[\"Lchain\"] == l)]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    ag = row[\"antigen_chain\"].values[0] # this gives us the antigen chain alone!\n",
    "    structure = parser.get_structure(name, pdb_path)\n",
    "    if ag not in [chain.id for chain in structure[0]]:\n",
    "        continue\n",
    "\n",
    "    # # make a distance matrix\n",
    "    heavy_Cas = []\n",
    "    \n",
    "    # # convert this into accessing entries in a generator?\n",
    "    heavy_chain = structure[0][h]\n",
    "    antigen_chain = structure[0][ag]\n",
    "    heavy_chains.append(heavy_chain)\n",
    "    antigen_chains.append(antigen_chain)\n",
    "\n",
    "    # node_features, edge_connections, edge_features = featurizer(heavy_chain, antigen_chain)\n",
    "print(heavy_chains, antigen_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8769710-5b8f-468b-a193-2248e5b87bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sa4139/rl_ag_dock/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# reference: https://medium.com/@volzhinnv/graph-convolutional-networks-gcn-all-you-need-to-know-code-implementation-fdfcde657b5c\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.nn import Sequential\n",
    "from torch_geometric.nn import global_add_pool\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINEConv.html?utm_source=chatgpt.com\n",
    "# class GCN(nn.Module):\n",
    "#     def __init__(self, num_node_features, hidden_dim, output_dimension):\n",
    "#         super(GCN, self).__init__()\n",
    "#         edge_mlp = nn.Sequential(\n",
    "#             nn.Linear(1, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim)\n",
    "#         )\n",
    "#         self.conv1 = GINEConv(nn.Linear(num_node_features, hidden_dim), edge_mlp)\n",
    "#         self.conv2 = GINEConv(nn.Linear(hidden_dim, hidden_dim), edge_mlp)\n",
    "#         self.conv3 = GINEConv(nn.Linear(hidden_dim, hidden_dim), edge_mlp)\n",
    "#         self.readout = nn.Linear(hidden_dim, output_dimension)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch):\n",
    "#         x = self.conv1(x, edge_index, edge_attr)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x, edge_index, edge_attr)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv3(x, edge_index, edge_attr)\n",
    "#         x = global_add_pool(x, batch)\n",
    "#         x = self.readout(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8b226b-5702-4c05-b4b7-75a53f5b7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dim = 6 \n",
    "# model = GCN(num_node_features=node_features.size(1),\n",
    "#             hidden_dim=128,\n",
    "#             output_dimension=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19941208-f6ba-4c1d-9a54-762b1f6896fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils import seeding\n",
    "from torch_geometric.data import Data\n",
    "from numpy import pi\n",
    "from Bio.PDB.vectors import rotaxis2m\n",
    "from Bio.PDB.vectors import Vector\n",
    "import random \n",
    "\n",
    "class DockingEnv(gym.Env):\n",
    "    # metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, heavy_chains, antigen_chains, featurizer, k=12, device='cpu'):\n",
    "        self.heavy_chains = heavy_chains\n",
    "        self.antigen_chains = antigen_chains\n",
    "        self.featurizer = featurizer\n",
    "        self.device = device\n",
    "        self.action_space = Box(low = np.array([0, 0, 0, 0, 0, 0]), high = np.array([10, 10, 10, 2*np.pi, 2*np.pi, 2*np.pi], dtype=np.float32))\n",
    "        self.observation_space = None\n",
    "        # store the starting coordinates of every antigen atom in a fixed order\n",
    "        self.current_step = 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        node_features, edge_index, edge_attr = self.featurizer(self.heavy_chain, self.antigen_chain, device=self.device)\n",
    "        state = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr) # store this as a Data type object!\n",
    "        # buffer.states.append(state)\n",
    "        trans = action[0:3]\n",
    "        rot = action[3:]\n",
    "        # print(action)\n",
    "        # multiply the rotation matrices wrt each of the directions\n",
    "        rotm = rotaxis2m(rot[0], Vector(1, 0, 0)) @ rotaxis2m(rot[1], Vector(0, 1, 0)) @ rotaxis2m(rot[2], Vector(0, 0, 1))\n",
    "        for atom in self.antigen_chain.get_atoms():\n",
    "            first_atom_coord = atom.coord\n",
    "            # going into a coordinate object, convert everything to numpy\n",
    "            atom.coord = rotm @ atom.coord + np.array(trans)\n",
    "            node_features, edge_index, edge_attr = self.featurizer(self.heavy_chain, self.antigen_chain, device=self.device)\n",
    "        next_state = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr) \n",
    "        next_reward = self._compute_reward()\n",
    "        # print(next_reward)\n",
    "        return next_state, next_reward, next_reward > -100 or self.current_step > 20, None\n",
    "        \n",
    "    def reset(self):\n",
    "        complex_i = random.randrange(len(self.antigen_chains))\n",
    "        print(complex_i)\n",
    "        self.antigen_chain = self.antigen_chains[complex_i]\n",
    "        self.heavy_chain = self.heavy_chains[complex_i]\n",
    "        self.starting_ag_coords = [atom.coord.copy() for atom in self.antigen_chain.get_atoms()]\n",
    "        self.current_step = 0\n",
    "        # reset antigen atoms to their stored starting positions, then apply a translation\n",
    "        for atom, start_coord in zip(self.antigen_chain.get_atoms(), self.starting_ag_coords):\n",
    "            atom.coord = start_coord + np.array([-10, 0, 0])\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        node_features, edge_index, edge_attr = self.featurizer(self.heavy_chain, self.antigen_chain, device=self.device)\n",
    "        # print(edge_index.shape, edge_attr.shape)\n",
    "        return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "    def _compute_reward(self):\n",
    "        node_features, edge_index, edge_attr = self.featurizer(self.heavy_chain, self.antigen_chain, device=self.device)\n",
    "        reward = -edge_attr.mean().item()\n",
    "        # print(reward)\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b75c73ec-19b3-49a1-a328-414fc5274b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.state_values = []\n",
    "        self.dones = []\n",
    "\n",
    "    def store_transition(self, state, action, logprob, reward, done, state_value):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.logprobs.append(logprob)\n",
    "        self.rewards.append(reward)\n",
    "        self.state_values.append(state_value)\n",
    "        self.dones.append(done)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.states.clear()\n",
    "        self.actions.clear()\n",
    "        self.logprobs.clear()\n",
    "        self.rewards.clear()\n",
    "        self.state_values.clear()\n",
    "        self.dones.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2edcb46-335e-4f7f-a99a-9b61a7be93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GINEConv, global_add_pool\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class GNNActorCritic(nn.Module):\n",
    "    def __init__(self, node_feature_dim, hidden_dim, action_dim, continuous_action=True):\n",
    "        super().__init__()\n",
    "        self.continuous_action = continuous_action\n",
    "        # print(hidden_dim)\n",
    "\n",
    "        nn1 = nn.Sequential(nn.Linear(node_feature_dim, hidden_dim), nn.ReLU(),\n",
    "                            nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINEConv(nn1, edge_dim=1)\n",
    "        nn2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                            nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINEConv(nn2, edge_dim=1)\n",
    "\n",
    "        self.feature_extractor = nn.ModuleList([self.conv1, self.conv2])\n",
    "\n",
    "        self.actor_head = nn.Linear(hidden_dim, action_dim)\n",
    "        self.critic_head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = global_add_pool(x, batch)  # Graph-level embedding\n",
    "        return self.actor_head(x), self.critic_head(x)\n",
    "\n",
    "    def evaluate_actions(self, x, edge_index, edge_attr, batch, actions):\n",
    "        action_mean, state_values = self.forward(x, edge_index, edge_attr, batch)\n",
    "        action_mean = torch.clamp(action_mean, -1e3, 1e3)\n",
    "        dist = torch.distributions.Normal(action_mean, 0.1)\n",
    "        logprobs = dist.log_prob(actions).sum(-1)\n",
    "        entropy = dist.entropy().sum(-1)\n",
    "        return state_values.squeeze(), logprobs, entropy\n",
    "\n",
    "    def select_action(self, state):\n",
    "        batch = torch.zeros(state.x.size(0), dtype=torch.long, device=state.x.device)\n",
    "        action_mean, state = self.forward(state.x, state.edge_index, state.edge_attr, batch)\n",
    "        action_mean = torch.clamp(action_mean, -1e3, 1e3)\n",
    "        dist = Normal(action_mean, 0.1)\n",
    "        action = dist.sample().squeeze()\n",
    "        logprob = dist.log_prob(action).sum(-1)\n",
    "        return action, logprob\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93decc8c-2187-46ef-a91f-b437d20cdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/saqib1707/RL-PPO-PyTorch\n",
    "class PPOAgent:\n",
    "    def __init__(\n",
    "            self, \n",
    "            obs_dim, \n",
    "            action_dim, \n",
    "            hidden_dim, \n",
    "            lr_actor, \n",
    "            lr_critic, \n",
    "            continuous_action_space=False, \n",
    "            num_epochs=10, \n",
    "            eps_clip=0.2, \n",
    "            action_std_init=0.6, \n",
    "            gamma=0.99,\n",
    "            entropy_coef=0.01,\n",
    "            value_loss_coef=0.5,\n",
    "            batch_size=64,\n",
    "            max_grad_norm=0.5,\n",
    "            device='cpu'\n",
    "        ):\n",
    "        self.gamma = gamma\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.eps_clip = eps_clip\n",
    "        self.value_loss_coef = value_loss_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.action_std_init = action_std_init\n",
    "        self.continuous_action_space = continuous_action_space\n",
    "        self.device = device\n",
    "\n",
    "        self.policy = GNNActorCritic(\n",
    "            node_feature_dim=obs_dim,  # this is the node feature size\n",
    "            hidden_dim=hidden_dim,\n",
    "            action_dim=action_dim,\n",
    "            continuous_action=True  # we want continuous 6D actions\n",
    "        ).to(device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': self.policy.feature_extractor.parameters()},\n",
    "            {'params': self.policy.actor_head.parameters(), 'lr': lr_actor},\n",
    "            {'params': self.policy.critic_head.parameters(), 'lr': lr_critic}\n",
    "        ])\n",
    "\n",
    "        self.buffer = RolloutBuffer()\n",
    "        self.mse_loss = nn.MSELoss()  # Initialize MSE loss\n",
    "\n",
    "\n",
    "    def compute_returns(self):\n",
    "        returns = []\n",
    "        discounted_reward = 0\n",
    "\n",
    "        for reward, done in zip(reversed(self.buffer.rewards), reversed(self.buffer.dones)):\n",
    "            if done:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + self.gamma * discounted_reward\n",
    "            returns.insert(0, discounted_reward)\n",
    "\n",
    "        returns = np.array(returns, dtype=np.float32)\n",
    "        returns = torch.flatten(torch.from_numpy(returns).float()).to(self.device)\n",
    "        return returns\n",
    "\n",
    "\n",
    "    def update_policy(self):\n",
    "        # Skip update if buffer is empty\n",
    "        if len(self.buffer.rewards) == 0:\n",
    "            self.buffer.clear()\n",
    "            return\n",
    "            \n",
    "        # print(len(self.buffer.rewards))\n",
    "        rewards_to_go = self.compute_returns()\n",
    "        # print(len(rewards_to_go))\n",
    "\n",
    "        # Handle Data objects - batch them instead of converting to numpy\n",
    "        from torch_geometric.data import Batch\n",
    "        states_list = [s.to(self.device) for s in self.buffer.states]\n",
    "        \n",
    "        # Convert actions, logprobs, state_vals to tensors on device\n",
    "        actions_list = []\n",
    "        for action in self.buffer.actions:\n",
    "            if isinstance(action, torch.Tensor):\n",
    "                actions_list.append(action.cpu().numpy() if action.is_cuda else action.numpy())\n",
    "            else:\n",
    "                actions_list.append(action)\n",
    "        actions = torch.from_numpy(np.array(actions_list, dtype=np.float32)).to(self.device)\n",
    "        \n",
    "        logprobs_list = []\n",
    "        for logprob in self.buffer.logprobs:\n",
    "            if isinstance(logprob, torch.Tensor):\n",
    "                logprobs_list.append(logprob.cpu().item() if logprob.is_cuda else logprob.item())\n",
    "            else:\n",
    "                logprobs_list.append(logprob)\n",
    "        old_logprobs = torch.from_numpy(np.array(logprobs_list, dtype=np.float32)).to(self.device)\n",
    "        \n",
    "        state_vals_list = []\n",
    "        for sv in self.buffer.state_values:\n",
    "            if isinstance(sv, torch.Tensor):\n",
    "                state_vals_list.append(sv.cpu().item() if sv.is_cuda else sv.item())\n",
    "            else:\n",
    "                state_vals_list.append(sv)\n",
    "        state_vals = torch.from_numpy(np.array(state_vals_list, dtype=np.float32)).to(self.device)\n",
    "\n",
    "        # print('stage-0:', rewards_to_go.shape, state_vals.shape)\n",
    "        # print('stage-1:', rewards_to_go.device, state_vals.device)\n",
    "        advantages = rewards_to_go - state_vals\n",
    "        \n",
    "        if len(advantages) == 1:\n",
    "            advantages = advantages - advantages.mean()\n",
    "        else:\n",
    "            adv_std = advantages.std()\n",
    "            if adv_std > 1e-8:\n",
    "                advantages = (advantages - advantages.mean()) / adv_std\n",
    "            else:\n",
    "                advantages = advantages - advantages.mean()\n",
    "        advantages = torch.clamp(advantages, min=-10.0, max=10.0)\n",
    "\n",
    "        # print(states.shape, actions.shape, old_logprobs.shape, state_vals.shape, advantages.shape, rewards_to_go.shape)\n",
    "\n",
    "        for _ in range(self.num_epochs):\n",
    "            # generate random indices for minibatch\n",
    "            indices = np.random.permutation(len(self.buffer.states))\n",
    "\n",
    "            for start_idx in range(0, len(self.buffer.states), self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "                # Batch Data objects\n",
    "                batch_states = Batch.from_data_list([states_list[i] for i in batch_indices])\n",
    "                batch_actions = actions[batch_indices]\n",
    "                batch_old_logprobs = old_logprobs[batch_indices]\n",
    "                batch_advantages = advantages[batch_indices]\n",
    "                batch_rewards_to_go = rewards_to_go[batch_indices]\n",
    "                \n",
    "                # evaluate old actions and values\n",
    "                state_values, logprobs, dist_entropy = self.policy.evaluate_actions(\n",
    "                    batch_states.x, batch_states.edge_index, batch_states.edge_attr, batch_states.batch, batch_actions\n",
    "                )\n",
    "                # print(logprobs.shape, batch_old_logprobs.shape)\n",
    "\n",
    "                logprob_diff = torch.clamp(logprobs - batch_old_logprobs.squeeze(-1), min=-10, max=10)\n",
    "                ratios = torch.exp(logprob_diff)\n",
    "\n",
    "                surr1 = ratios * batch_advantages\n",
    "                surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * batch_advantages\n",
    "\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "                state_values_flat = state_values.view(-1)\n",
    "                critic_loss = 0.5 * self.mse_loss(state_values_flat, batch_rewards_to_go)\n",
    "                loss = actor_loss + self.value_loss_coef * critic_loss - self.entropy_coef * dist_entropy.mean()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "        \n",
    "        self.buffer.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e798214-9ee8-435d-ba83-11750717aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# code taken from https://github.com/saqib1707/RL-PPO-PyTorch/blob/main/src/model.py\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.optim import Adam\n",
    "# import gym\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, hidden_size=64):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(inp_dim, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        # convert observation to tensor if it's a numpy array\n",
    "        if isinstance(obs, np.ndarray):\n",
    "            obs = torch.tensor(obs, dtype=torch.float)\n",
    "\n",
    "        x = self.relu(self.layer1(obs))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        out = self.layer3(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ProximalPolicyOptimization:\n",
    "    def __init__(self, env, seed=43, lr=1e-3):\n",
    "        assert type(env.observation_space) == Box, \"This example only works for envs with continuous state spaces.\"\n",
    "        assert type(env.action_space) == Box, \"This example only works for envs with continuous action spaces.\"\n",
    "        self._set_seed(seed)\n",
    "\n",
    "        # extract environment information\n",
    "        self.env = env\n",
    "        self.obs_dim = env.observation_space.shape[0]    # = ns\n",
    "        self.act_dim = env.action_space.shape[0]    # = na\n",
    "        print(f\"Observation Dimension: {self.obs_dim} | Action Dimension: {self.act_dim}\")\n",
    "\n",
    "        # initialize actor and critic networks\n",
    "        self.actor = FeedForwardNN(inp_dim=self.obs_dim, out_dim=self.act_dim)\n",
    "        self.critic = FeedForwardNN(inp_dim=self.obs_dim, out_dim=1)\n",
    "\n",
    "        self.actor_optimizer = Adam(self.actor.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "        self.critic_optimizer = Adam(self.critic.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "        # initialize action covariance matrix for exploration\n",
    "        self.act_cov = torch.diag(torch.full(size=(self.act_dim,), fill_value=0.5))    # (na,na)\n",
    "        # print(self.action_cov_mat)\n",
    "\n",
    "        # initialize logger\n",
    "        self.logger = {\n",
    "            'delta_t': time.time_ns(),\n",
    "            't_so_far': 0,\n",
    "            'i_so_far': 0,\n",
    "            'batch_lens': [],\n",
    "            'batch_rewards': [],\n",
    "            'actor_losses': [],\n",
    "        }\n",
    "\n",
    "\n",
    "    def learn(self, total_timesteps, timesteps_per_batch, max_eps_len, num_updates_per_itr, clip_thresh=0.2, save_every=1000, gamma=0.9):\n",
    "        t_so_far = 0    # timesteps simulated so far\n",
    "        i_so_far = 0\n",
    "\n",
    "        while t_so_far < total_timesteps:\n",
    "            # roll out multiple trajectories\n",
    "            batch_obs, batch_actions, batch_logprobs, batch_reward_to_go, batch_eps_lens = self.collect_rollouts(\n",
    "                timesteps_per_batch, \n",
    "                max_eps_len, \n",
    "                gamma\n",
    "            )\n",
    "            print(\"stage-1:\", batch_obs.shape, batch_actions.shape, batch_logprobs.shape, batch_reward_to_go.shape)\n",
    "\n",
    "            # calculate how many timesteps collected in this batch\n",
    "            t_so_far += np.sum(batch_eps_lens)\n",
    "            i_so_far += 1\n",
    "\n",
    "            # logging timesteps and iterations so far\n",
    "            self.logger['t_so_far'] = t_so_far\n",
    "            self.logger['i_so_far'] = i_so_far\n",
    "\n",
    "            # calculate value function V_{phi, k} using critic model\n",
    "            V, _ = self.evaluate(batch_obs, batch_actions)\n",
    "\n",
    "            # calculate advantage function A_k\n",
    "            A_k = batch_reward_to_go - V.detach()\n",
    "\n",
    "            # normalize advantage function\n",
    "            A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10)\n",
    "\n",
    "            for _ in range(num_updates_per_itr):\n",
    "                # calculate pi_theta(at | st)\n",
    "                curr_V, curr_logprobs = self.evaluate(batch_obs, batch_actions)\n",
    "\n",
    "                # calcuate ratios\n",
    "                ratios = torch.exp(curr_logprobs - batch_logprobs)\n",
    "\n",
    "                # calcuate surrogate losses\n",
    "                surr1 = ratios * A_k\n",
    "\n",
    "                # clips ratio to make sure we are not stepping too far in any direction during gradient ascent\n",
    "                surr2 = torch.clamp(ratios, 1 - clip_thresh, 1 + clip_thresh) * A_k\n",
    "\n",
    "                # calculate actor and critic losses\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "                critic_loss = nn.MSELoss()(curr_V, batch_reward_to_go)\n",
    "\n",
    "                # calculate gradients and backpropagate for actor network\n",
    "                self.actor_optimizer.zero_grad()\n",
    "                actor_loss.backward(retain_graph=True)\n",
    "                self.actor_optimizer.step()\n",
    "\n",
    "                # calculate gradients and backpropagate for critic network\n",
    "                self.critic_optimizer.zero_grad()\n",
    "                critic_loss.backward()\n",
    "                self.critic_optimizer.step()\n",
    "\n",
    "                self.logger['actor_losses'].append(actor_loss.detach())\n",
    "            \n",
    "            # print a summary of the training so far\n",
    "            self._log_summary(total_timesteps)\n",
    "\n",
    "            if i_so_far % save_every == 0:\n",
    "                torch.save(self.actor.state_dict(), './checkpoints/ppo_actor.pth')\n",
    "                torch.save(self.critic.state_dict(), './checkpoints/ppo_critic.pth')\n",
    "\n",
    "\n",
    "    def evaluate(self, batch_obs, batch_actions):\n",
    "        value = self.critic(batch_obs).squeeze()\n",
    "        # print(value.shape)\n",
    "\n",
    "        # calculate the log probabilities of batch actions using most recent actor network\n",
    "        mean = self.actor(batch_obs)\n",
    "        # print(\"Stage-2\", mean.shape, self.action_cov_mat.shape, batch_obs.shape, batch_actions.shape)\n",
    "        dist = MultivariateNormal(mean, self.act_cov)\n",
    "        # print(\"This would be printed\", dist)\n",
    "        logprob = dist.log_prob(batch_actions)\n",
    "        # print(\"This would not be printed\", dist)\n",
    "        return value, logprob\n",
    "\n",
    "\n",
    "    def collect_rollouts(self, max_timesteps, max_eps_len, gamma):\n",
    "        observations = []\n",
    "        actions = []\n",
    "        logprobs = []\n",
    "        rewards = []\n",
    "        eps_lens = []\n",
    "\n",
    "        t = 0\n",
    "        while t < max_timesteps:\n",
    "            # reset environment and get initial observation\n",
    "            obs, _ = self.env.reset()\n",
    "            done = False\n",
    "            # print(\"Stage-2 after reset:\", obs)\n",
    "\n",
    "            eps_rewards = []\n",
    "            for step in range(max_eps_len):\n",
    "                action, logprob = self.select_action(obs)\n",
    "                next_obs, reward, done, _, _ = self.env.step(action)\n",
    "                t += 1\n",
    "\n",
    "                # collect observation, action, log probabilities and reward\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                logprobs.append(logprob)\n",
    "                eps_rewards.append(reward)\n",
    "\n",
    "                obs = next_obs\n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # collect episode length and rewards\n",
    "            rewards.append(eps_rewards)\n",
    "            eps_lens.append(step+1)\n",
    "\n",
    "        # reshape numpy data as tensors\n",
    "        observations = torch.from_numpy(np.array(observations, dtype=np.float32))    # [max_timesteps, ns]\n",
    "        actions = torch.from_numpy(np.array(actions, dtype=np.float32))    # [max_timesteps, na]\n",
    "        actions = actions.unsqueeze(1)\n",
    "        logprobs = torch.from_numpy(np.array(logprobs, dtype=np.float32))    # [max_timesteps]\n",
    "        rewards_to_go = self.compute_reward_to_go(rewards, gamma)\n",
    "        # print(\"Stage-0:\", np.array(batch_rewards).shape, batch_reward_to_go.shape)\n",
    "        # batch_episode_lengths = torch.tensor(batch_episode_lengths, dtype=torch.float32)\n",
    "\n",
    "        # log the episodic rewards and lengths\n",
    "        self.logger['batch_rewards'] = rewards\n",
    "        self.logger['batch_lengths'] = eps_lens\n",
    "        return observations, actions, logprobs, rewards_to_go, eps_lens\n",
    "\n",
    "\n",
    "    def compute_reward_to_go(self, rewards, gamma):\n",
    "        \"\"\"\n",
    "        Compute the discounted reward-to-go for each timestep in each episode\n",
    "        Args:\n",
    "            rewards: list of lists, where each inner list contains rewards for an episode\n",
    "            gamma: discount  for future rewards\n",
    "        Returns:\n",
    "            rewards_to_go: list of reward-to-go for each timestep in each episode\n",
    "        \"\"\"\n",
    "        rewards_to_go = []\n",
    "\n",
    "        # iterate through each episodic rewards\n",
    "        for eps_rewards in rewards:\n",
    "            eps_rewards_to_go = []\n",
    "            reward_sum = 0\n",
    "\n",
    "            for r in reversed(eps_rewards):\n",
    "                reward_sum = r + gamma * reward_sum    # discounted reward\n",
    "                eps_rewards_to_go.append(reward_sum)\n",
    "\n",
    "            eps_rewards_to_go = eps_rewards_to_go[::-1]\n",
    "            rewards_to_go.append(eps_rewards_to_go)\n",
    "\n",
    "        # convert reward-to-go into tensor\n",
    "        rewards_to_go = np.array(rewards_to_go, dtype=np.float32)\n",
    "        rewards_to_go = torch.flatten(torch.from_numpy(rewards_to_go))\n",
    "\n",
    "        return rewards_to_go\n",
    "\n",
    "\n",
    "    def estimate_action(self, obs):\n",
    "        print(\"Stage-3:\", obs)\n",
    "        # query the actor network for mean of the distribution\n",
    "        mean = self.actor(obs)\n",
    "\n",
    "        # create multivariate normal distribution\n",
    "        dist = MultivariateNormal(mean, self.act_cov)\n",
    "\n",
    "        # sample an action from the distribution and compute its logprob\n",
    "        action = dist.sample()\n",
    "        logprob = dist.log_prob(action)\n",
    "\n",
    "        return action.detach().numpy(), logprob.detach()\n",
    "\n",
    "\n",
    "    def _set_seed(self, seed):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        print(f\"Successfully set seed everywhere: {seed}\")\n",
    "\n",
    "\n",
    "    def _log_summary(self, total_timesteps):\n",
    "        delta_t = self.logger['delta_t']\n",
    "        self.logger['delta_t'] = time.time_ns()\n",
    "        delta_t = round((self.logger['delta_t'] - delta_t) / 1e9, 4)\n",
    "\n",
    "        avg_episode_lens = np.mean(self.logger['batch_lengths'])\n",
    "        avg_episode_rewards = round(np.mean([np.sum(ep_rewards) for ep_rewards in self.logger['batch_rewards']]), 4)\n",
    "        avg_actor_loss = round(np.mean([losses.mean() for losses in self.logger['actor_losses']]), 4)\n",
    "\n",
    "        print(f\"{self.logger['t_so_far']}/{total_timesteps} | Avg Loss: {avg_actor_loss} | Avg Ep Len: {avg_episode_lens} | Avg Ep Reward: {avg_episode_rewards} | Itr {self.logger['i_so_far']} took {delta_t} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de673a8e-6a1a-4ef1-ab60-e3b5de12b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:27<08:37, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:54<08:08, 27.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:27<08:27, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:00<08:20, 31.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:27<07:26, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [02:55<06:44, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [05:15<14:09, 65.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [05:42<10:36, 53.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:15<08:36, 46.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [06:16<05:25, 32.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [08:37<09:51, 65.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [10:59<11:51, 88.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [11:32<08:25, 72.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [12:06<06:03, 60.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [14:28<07:06, 85.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [14:56<04:31, 67.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [17:18<04:30, 90.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [19:40<03:31, 105.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [22:01<01:56, 116.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [24:22<00:00, 73.11s/it] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "node_feature_dim = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "env = DockingEnv(heavy_chains, antigen_chains, featurizer, device=device)\n",
    "agent = PPOAgent(\n",
    "    obs_dim=node_feature_dim,\n",
    "    action_dim=6,\n",
    "    hidden_dim=128,\n",
    "    lr_actor=1e-4,\n",
    "    lr_critic=1e-4,\n",
    "    continuous_action_space=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "num_episodes = 20\n",
    "rewards = []\n",
    "for ep in tqdm(range(num_episodes)):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    ep_reward = []\n",
    "    while not done:\n",
    "        action, logprob = agent.policy.select_action(state)\n",
    "        \n",
    "        # Compute state value\n",
    "        batch = torch.zeros(state.x.size(0), dtype=torch.long, device=state.x.device)\n",
    "        _, state_value = agent.policy.forward(state.x, state.edge_index, state.edge_attr, batch)\n",
    "        state_value = state_value.squeeze().item()\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action.detach().cpu().numpy() if isinstance(action, torch.Tensor) else action)\n",
    "        ep_reward.append(reward)\n",
    "        \n",
    "        # Save in buffer\n",
    "        agent.buffer.states.append(state)\n",
    "        agent.buffer.actions.append(action.detach().cpu().numpy() if isinstance(action, torch.Tensor) else action)\n",
    "        agent.buffer.rewards.append(reward)\n",
    "        agent.buffer.dones.append(done)\n",
    "        agent.buffer.logprobs.append(logprob.detach().cpu().item() if isinstance(logprob, torch.Tensor) else logprob)\n",
    "        agent.buffer.state_values.append(state_value)\n",
    "        \n",
    "        state = next_state\n",
    "    ep_reward = sum(ep_reward)/len(ep_reward)\n",
    "    rewards.append(ep_reward)\n",
    "    agent.update_policy()\n",
    "    \n",
    "plt.title(f\"Overall Rewards\")\n",
    "plt.plot(rewards)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c55ea2-b742-4aaa-a2e2-b51783741bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl_ag_dock)",
   "language": "python",
   "name": "rl_ag_dock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
