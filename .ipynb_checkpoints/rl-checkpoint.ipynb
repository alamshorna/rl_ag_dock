{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03f6681-4477-4afe-a406-bd29f977d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start, let's try to implement a REINFORCE algorithm (policy gradient)\n",
    "# we only need some sort of featurizer, \n",
    "# a policy graph network, \n",
    "# and the reinforcement learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed855911-7c18-4526-a48a-a9878d6e5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # note: code borrowed from gaeun\n",
    "import os \n",
    "import yaml\n",
    "\n",
    "yamls_path = \"/project/liulab/gkim/antigen_prediction/eval_boltz_on_sabdab/all_yaml_outdir\"\n",
    "pdbs_path = \"/project/liulab/gkim/antigen_prediction/data/renumbered_sabdab_pdb_files/pdb_files\"\n",
    "\n",
    "def get_chain_info_from_pdb(pdb_path, yaml_path):\n",
    "    \"\"\"Get chain information from YAML file.\"\"\"    \n",
    "    if not os.path.exists(pdb_path):\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    if not os.path.exists(yaml_path):\n",
    "        print(f\"No YAML file found at {yaml_path}\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            yaml_data = yaml.safe_load(f)\n",
    "        \n",
    "        # Extract chain IDs and sequences from YAML data\n",
    "        # Assume the first sequence is heavy and the second sequence is light\n",
    "        # UNLESS there are more than 2 sequences\n",
    "        h_chain = None\n",
    "        l_chain = None\n",
    "        h_seq_yaml = None\n",
    "        l_seq_yaml = None\n",
    "\n",
    "        # Look for sequences in the YAML data\n",
    "        if 'sequences' in yaml_data and isinstance(yaml_data['sequences'], list):\n",
    "            sequences = yaml_data['sequences']\n",
    "            if len(sequences) == 2:\n",
    "                h_chain = sequences[0]['protein']['id']  # First sequence is heavy\n",
    "                l_chain = sequences[1]['protein']['id']  # Second sequence is light\n",
    "                h_seq_yaml = sequences[0]['protein']['sequence']\n",
    "                l_seq_yaml = sequences[1]['protein']['sequence']\n",
    "            elif len(sequences) > 2:\n",
    "                # first sequence is antigen (for multimer predictions)\n",
    "                h_chain = sequences[1]['protein']['id']  # Second sequence is heavy\n",
    "                l_chain = sequences[2]['protein']['id']  # Third sequence is light\n",
    "                h_seq_yaml = sequences[1]['protein']['sequence']\n",
    "                l_seq_yaml = sequences[2]['protein']['sequence']\n",
    "        \n",
    "        if 'antigen' in yaml_data and isinstance(yaml_data['antigen'], list):\n",
    "            antigen = yaml_data['antigen'][0]['protein']['sequence']\n",
    "        else:\n",
    "            antigen = None\n",
    "        \n",
    "        return h_chain, l_chain, h_seq_yaml, l_seq_yaml, antigen\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading YAML file for {yaml_path}: {e}\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0625a31-544e-4346-9b53-b4f49da6c049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pdb', 'Hchain', 'Lchain', 'model', 'antigen_chain', 'antigen_type',\n",
      "       'antigen_het_name', 'antigen_name', 'short_header', 'date', 'compound',\n",
      "       'organism', 'heavy_species', 'light_species', 'antigen_species',\n",
      "       'authors', 'resolution', 'method', 'r_free', 'r_factor', 'scfv',\n",
      "       'engineered', 'heavy_subclass', 'light_subclass', 'light_ctype',\n",
      "       'affinity', 'delta_g', 'affinity_method', 'temperature', 'pmid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sd_pd = pd.read_csv(\"sabdab_summary_all.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b37f5fd0-d4a2-4570-bacb-3c391a4a038d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3145784921.py, line 12)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def featurizer(heavy_chain, ag_chain, residues, dist_matrix):\n",
    "    # to make this compatible with the pytorch geometric GNN library, we have to \n",
    "    # create a tensor for the nodes\n",
    "    # a tensor for the edges\n",
    "    # and a tensor for the edge features\n",
    "    nodes_features = torch.randn(len(residues[0]) + len(residues[1]), 1)\n",
    "    \n",
    "    \n",
    "    # for residue in \n",
    "    # print(heavy_chain, ag_chain, residues[0], residues[1])\n",
    "    for hr in residues[0]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c0ede74-6a5e-4586-92af-d12f4331f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing YAML files:   0%|          | 0/6920 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'distance_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# flatten and unravel :)\u001b[39;00m\n\u001b[32m     39\u001b[39m bottom_k_indices = np.unravel_index(bottom_k, dist_matrix.shape)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m featurizer(heavy_chain, antigen_chain, bottom_k_indices, \u001b[43mdistance_matrix\u001b[49m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'distance_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "k = 50\n",
    "\n",
    "from Bio.PDB import PDBList, PDBParser, Select, PDBIO\n",
    "import numpy as np\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "for yaml_file in tqdm(os.listdir(yamls_path), desc=\"Processing YAML files\"):\n",
    "    yaml_path = os.path.join(yamls_path, yaml_file)\n",
    "    name = yaml_file.split('.')[0]\n",
    "    pdb_file = name + '.pdb'\n",
    "    pdb_path = os.path.join(pdbs_path, pdb_file)\n",
    "    # we'll use Gauen's function because it already maps from the name to the pdb that is already downloaded on the server...\n",
    "    h, l, _, _, _ = get_chain_info_from_pdb(pdb_path, yaml_path)\n",
    "    row = sd_pd[(sd_pd[\"pdb\"] == name) & (sd_pd[\"Hchain\"] == h) & (sd_pd[\"Lchain\"] == l)]\n",
    "    ag = row[\"antigen_chain\"].item() # this gives us the antigen chain alone!\n",
    "    structure = parser.get_structure(name, pdb_path)\n",
    "\n",
    "    # make a distance matrix\n",
    "    heavy_Cas = []\n",
    "    \n",
    "    # convert this into accessing entries in a generator?\n",
    "    heavy_chain = structure[0][h]\n",
    "    antigen_chain = structure[0][ag]\n",
    "\n",
    "    # construct the distance matrix\n",
    "    heavy_coords = np.array([res['CA'].coord for res in heavy_chain if 'CA' in res])\n",
    "    antigen_coords = np.array([res['CA'].coord for res in antigen_chain if 'CA' in res])\n",
    "    dist_matrix = np.linalg.norm(\n",
    "        heavy_coords[:, np.newaxis, :] - antigen_coords[np.newaxis, :, :],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    # https://numpy.org/devdocs/reference/generated/numpy.argpartition.html\n",
    "    # only sort the bottom k\n",
    "    bottom_k = np.argpartition(dist_matrix.flatten(), k)[:k]\n",
    "    # flatten and unravel :)\n",
    "    bottom_k_indices = np.unravel_index(bottom_k, dist_matrix.shape)\n",
    "\n",
    "    featurizer(heavy_chain, antigen_chain, bottom_k_indices, dist_matrix)\n",
    "    \n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8769710-5b8f-468b-a193-2248e5b87bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl_ag_dock)",
   "language": "python",
   "name": "rl_ag_dock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
